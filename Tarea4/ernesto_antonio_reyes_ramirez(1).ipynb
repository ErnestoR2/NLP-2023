{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0e4099",
   "metadata": {},
   "source": [
    "# Ernesto Antonio Retes Ramírez \n",
    "\n",
    "# Procesamiento de Lenguaje Natural \n",
    "\n",
    "# Tarea 4: Statistical Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaee2fd",
   "metadata": {},
   "source": [
    "# AYUDA\n",
    "\n",
    "Mi compañero Daniel me ayudó en el punto 2.1 para la creación del corpus y del vocabulario. Me ayudó de la siguiente manera: yo tenía duda sobre la asignación de $<s>$ y $<s>$, ya que no tenía claro cuantos EOS tenía que agregar. Él me explicó que era necesario agregar un EOS para distinguir entre oraciones, pero que con uno solo bastaba, no era como en el caso de BOS, ya que al estar tomando los dos elementos por detrás de ti en los modelos de trigramas, no necesita agregar más para calcular todas las probabilidades. También me dijo que, desde su punto de vista, podría ser ventajoso agregar dos BOS a cada tweet y ese corpus utilizar para todos los modelos, ya que de cierta forma queremos trabajar sobre el mismo conjunto de datos para poder medirlo con la perplejidad y compararlos.\n",
    "\n",
    "\n",
    "Por otro lado, ayudé a mi compañero Daniel con respecto al punto 2.3, ya que estaba utilizando la definición exacta de perplejidad la cual da unos ciertos problemas numéricos. Mi ayuda fue mostrarle y explicarle otro forma de clacular la perplejidad utilizando la entropía, que es un método el cual explican en el capitulo de Dan como tema avanzado en el final. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056746e",
   "metadata": {},
   "source": [
    "# 2. Modelo de Lenguaje y Evaluación "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24601a9",
   "metadata": {},
   "source": [
    "1. Preprocese todos los tuits de agresividad (positivos y negativos) según su intuición para construir un buen corpus para un modelo de lenguaje (e.g., solo palabras en minúscula, etc.). Agregue tokens especiales de $<s>$ y $</s>$ según usted considere (e.g., al inicio y final de cada tuit). Defina su vocabulario y enmascare con <unk> toda palabra que no esté en su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3335ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wget\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2719c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus,path_truth):\n",
    "    tr_text = []\n",
    "    tr_y = []\n",
    "    \n",
    "    with open(path_corpus,\"r\",encoding=\"utf-8\") as f_corpus, open(path_truth,\"r\",encoding=\"utf-8\") as f_truth:\n",
    "        for twitt in f_corpus:\n",
    "            tr_text += [twitt]\n",
    "        for label in f_truth:\n",
    "            tr_y += [label]\n",
    "    return tr_text,tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d35c380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el conjunto de datos \n",
    "tr_txt, tr_y = get_texts_from_file(\"mex_train.txt\",\"mex_train_labels.txt\")\n",
    "test_txt, test_y = get_texts_from_file(\"mex_val.txt\",\"mex_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "38dbc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, val_txt = train_test_split(tr_txt, test_size=616, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2eb766b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "68d59bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos minuscula el texto y agregamos inicio(<s>) y final(</s>) de tweet dependiendo el caso\n",
    "corpus = []\n",
    "\n",
    "for doc in tr_txt:\n",
    "    corpus += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "fdist1 = nltk.FreqDist(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "77fe6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key],key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f4e69216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos nuestros vocabularios con las 10000 palabras más frecuentes\n",
    "Vocabulary = sortFreqDict(fdist1)\n",
    "Vocabulary = Vocabulary[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5ab7932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indices = dict()\n",
    "cont = 0 \n",
    "\n",
    "for weight, word in Vocabulary:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1ad444d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado nuestro vocabulario, las palabras que no están en él las cambiamos por \"unk\"\n",
    "train = [ w if w in dict_indices else '<unk>' for w in corpus]\n",
    "N = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "11e6a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulario con unk\n",
    "fdist2 = nltk.FreqDist(train)\n",
    "V = sortFreqDict(fdist2)\n",
    "\n",
    "dict_ind = dict()\n",
    "cont = 0 \n",
    "\n",
    "for weight, word in V:\n",
    "    dict_ind[word] = cont\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f724546",
   "metadata": {},
   "source": [
    "El corpus que creamos llamdo train lo hice de la siguiente forma. A cada tweet le agregé dos $<s>$ al inicio y un $</s>$ al final. Esto ya que queremos trabajar hasta con trigramas. Tokenize los tweets y formé mi vocabulario con las 10000 palabras más frecuentes. Finalmente enmascaré las palabras que no pertenecen al corpus con el caracter $<unk>$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc51273",
   "metadata": {},
   "source": [
    "2. Entrene tres modelos de lenguaje sobre todos los tuits: Unigramas(wn1), bigramas(wn1),trigramas(wn1). Para cada uno proporcione una interfaz (función) sencilla para Pn−grama(wn1)y Pn−grama(wn1|wn−1n−N+1). Los modelos deben tener una estrategia común para lidiar consecuencias no vistas. Puede optar por un suavizamiento Laplace o un Good-Turingdiscounting. Muestre un par de ejemplos de como funciona, al menos uno con unapalabra fuera del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfe490",
   "metadata": {},
   "source": [
    "UNIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "da68d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular la probabilidad de una palabra    \n",
    "\n",
    "P_uni = {}\n",
    "N = len(train)\n",
    "len_V = len(V)\n",
    "for frec, word in V:\n",
    "    P_uni[word] = (frec+1) / (N+len_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4b66a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contiene las frecuencias de cada palabra\n",
    "freqUni = Counter(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2b957",
   "metadata": {},
   "source": [
    "Probando algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c48608e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008255638314495547"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"madre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5984374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08556869281386183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"<s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6941edd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023048075420594824"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5b806dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012587461152490582"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"puto\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423d9ff",
   "metadata": {},
   "source": [
    "BIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "82a0f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos nuestros bigramas\n",
    "bigrams = [(item[0],item[1]) for item in nltk.bigrams(train)]\n",
    "freqBigr = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b805af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_bigr(bigram, freq={}, freqU={}, cond=False):\n",
    "    if cond:\n",
    "        if bigram not in freq:\n",
    "            return 1 / (freqU[bigram[0]]+len_V)\n",
    "        return (freq[bigram]+1) / (freqU[bigram[0]]+len_V)\n",
    "    \n",
    "    else:\n",
    "        ans = np.log(P_uni[bigram[1]])\n",
    "        ans += np.log((freq[bigram]+1) / (freqU[bigram[0]]+len_V))\n",
    "        return  np.exp(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98b353a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('<s>', '<s>')\n",
      "0.021240272290855868\n",
      "\n",
      "P( <s> | <s> )\n",
      "0.2482248073727149\n"
     ]
    }
   ],
   "source": [
    "bigram = bigrams[0]\n",
    "print('P', bigram)\n",
    "print(P_bigr(bigram, freqBigr, freqUni))\n",
    "print('\\nP(', bigram[1],'|',bigram[0],')')\n",
    "print(P_bigr(bigram, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a21c7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('</s>', '<s>')\n",
      "0.028245864973321128\n",
      "\n",
      "P( <s> | </s> )\n",
      "0.3300957867238261\n"
     ]
    }
   ],
   "source": [
    "bigram = bigrams[23]\n",
    "print('P', bigram)\n",
    "print(P_bigr(bigram, freqBigr, freqUni))\n",
    "print('\\nP(', bigram[1],'|',bigram[0],')')\n",
    "print(P_bigr(bigram, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426b9fb",
   "metadata": {},
   "source": [
    "Notemos que de tener un signo de final siga uno de inicio es un hecho muy probable, tomando en cuenta que hemos hecho un\n",
    "suavizamiento laplaciano donde toda la masa de probabilidad se ha movido. La probabilidad no es cerca a 1 porque hemos movido toda la masa de probabilidad con el suavizamiento laplaciano. Pero aún así es muy alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3e448",
   "metadata": {},
   "source": [
    "TRIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6c012e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [(item[0],item[1],item[2]) for item in nltk.trigrams(train)]\n",
    "freqTrigr = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "70583f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_trigr(trigram, freq={}, freqB={}, freqU={}, cond=False):\n",
    "    lenVB = len(freqB)\n",
    "    if cond:\n",
    "        if trigram not in freq:\n",
    "            return 1 / (freqB[(trigram[0],trigram[1])] + lenVB)\n",
    "        return (freq[trigram]+1) / (freqB[(trigram[0],trigram[1])] + lenVB)\n",
    "    \n",
    "    else:\n",
    "        ans = np.log(P_uni[trigram[2]])\n",
    "        ans += np.log(P_bigr((trigram[1],trigram[2]), freqB, freqU, True))\n",
    "        ans += np.log((freq[trigram]+1) / (freqB[(trigram[0],trigram[1])] + lenVB))\n",
    "        return  np.exp(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dafcf0",
   "metadata": {},
   "source": [
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "828f7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('<s>', 'vamos', 'a')\n",
      "2.820764452218357e-09\n",
      "\n",
      "P( a | <s> vamos )\n",
      "8.213383708753413e-05\n"
     ]
    }
   ],
   "source": [
    "trigram = trigrams[1]\n",
    "print('P', trigram)\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni))\n",
    "print('\\nP(', trigram[2],'|',trigram[0],trigram[1],')')\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40c6441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('</s>', '<s>', '<s>')\n",
      "0.0019519629615347169\n",
      "\n",
      "P( <s> | </s> <s> )\n",
      "0.09189914963449201\n"
     ]
    }
   ],
   "source": [
    "trigram = trigrams[23]\n",
    "print('P', trigram)\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni))\n",
    "print('\\nP(', trigram[2],'|',trigram[0],trigram[1],')')\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ac3c3",
   "metadata": {},
   "source": [
    "Como se esperaba el trigrama de un signo final con dos iniciales es uno que esperaríamos tenga probabilidad alta ya que se repite muchísimo, al nosotros agregarlo a cada tweet. Otro trigrama como el primero es poco común por eso tiene una probabilidad muy baja aunque como podemos ver no es cero. Por lo que en general, los resultados de cada uno de los modelos son consistentes con lo esperado, y podríamos decir son buenos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f5fa6",
   "metadata": {},
   "source": [
    "3. Construya un modelo interpolado con valores λ fijos:P̂(wn|wn−2wn−1) = λ1P(wn|wn−2wn−1) + λ2P(wn|wn−1) + λ3P(wn)Para ello experimente con el modelo en particiones estratificadas de 80%, 10% y 10%\n",
    "para entrenar (train), ajuste de parámetros (val) y prueba (test) respectivamente. Muestrecomo bajan o suben las perplejidades en validación, finalmente pruebe una vez entest. Para esto puede explorar algunos valores ⃗λ y elija el mejor. Pruebe las siguientes:[1/3, 1/3, 1/3],[.4, .4, .2],[.2, .4, .4],[.5, .4, .1] y [.1, .4, .5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2795d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def interpolated_p(trigram, l1, l2, l3):\n",
    "    return l3*P_trigr(trigram, freqTrigr, freqBigr, freqUni,cond=True) + l2*P_bigr((trigram[1],trigram[2]),freqBigr, freqUni,cond=True) + l1*P_uni[trigram[2]]\n",
    "\n",
    "def perplexity(corpus, l1, l2, l3,s):\n",
    "    N = len(corpus) - 2*s\n",
    "    p = 0\n",
    "    \n",
    "    p = sum([np.log(interpolated_p((corpus[i-2],corpus[i-1],corpus[i]),l1,l2,l3)) for i in range(2,len(corpus))])\n",
    "    H = (-1/N)*p\n",
    "    return 2**H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e1a0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamos el conjunto de validación \n",
    "validation = []\n",
    "\n",
    "for doc in val_txt:\n",
    "    validation += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "validation = [ w if w in dict_indices else '<unk>' for w in validation]\n",
    "s = len(val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f3feedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.3333333333333333 l2=0.3333333333333333 l3=0.3333333333333333 perp=110.55313668294157\n",
      "for l1=0.4 l2=0.4 l3=0.2 perp=97.7721684986476\n",
      "for l1=0.2 l2=0.4 l3=0.4 perp=129.78369190056088\n",
      "for l1=0.5 l2=0.4 l3=0.1 perp=88.37834023431512\n",
      "for l1=0.1 l2=0.4 l3=0.5 perp=164.34575664442343\n"
     ]
    }
   ],
   "source": [
    "# Tests 1\n",
    "l1 = 1/3;l2 = 1/3;l3 = 1/3\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.4;l2 = 0.4;l3 =0.2\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.2;l2 =0.4;l3 =0.4\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.5;l2 =0.4;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.1;l2=0.4;l3 =0.5\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5520ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.18 l2=0.8 l3=0.02 perp=106.26929194702721\n",
      "for l1=0.06 l2=0.8 l3=0.14 perp=140.89781629360468\n",
      "for l1=0.05 l2=0.85 l3=0.1 perp=141.9018502613383\n",
      "for l1=0.7 l2=0.15 l3=0.15 perp=87.02942984781916\n",
      "for l1=0.8 l2=0.1 l3=0.1 perp=83.68766447504112\n"
     ]
    }
   ],
   "source": [
    "# Tests 2\n",
    "l1 =0.18;l2=0.8;l3=0.02\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.06;l2 = 0.8;l3 =0.14\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.05;l2 =0.85;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.7;l2 =0.15;l3 =0.15\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2=0.1;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44e0dfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.9 l2=0.05 l3=0.05 perp=81.1056816940672\n",
      "for l1=0.8 l2=0.15 l3=0.05 perp=80.79218952940077\n",
      "for l1=0.8 l2=0.05 l3=0.15 perp=87.05767624051929\n",
      "for l1=1 l2=0 l3=0 perp=79.20123264533848\n"
     ]
    }
   ],
   "source": [
    "# Test 3\n",
    "l1 = 0.9;l2 =0.05;l3 =0.05\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2 =0.15;l3 =0.05\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2=0.05;l3 =0.15\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 1;l2=0;l3 =0\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908294e0",
   "metadata": {},
   "source": [
    "Vamos a tomar los valores de $\\lambda_1 = 0.7, \\lambda_2 = 0.15, \\lambda_3 = 0.15$, los cuales presentaron un nivel de perplejidad de 87.03 apróximadamente, el cual a comparación de las demás pruebas, es un valor bajo pero sin llegar a ser de los más bajos para evitar el sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae34fad",
   "metadata": {},
   "source": [
    "Finalmente probabmos dichos valores una vez con el conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f704527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamos el conjunto de test\n",
    "test = []\n",
    "\n",
    "for doc in test_txt:\n",
    "    test += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "test = [ w if w in dict_indices else '<unk>' for w in test]\n",
    "t = len(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4acba65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.7 l2=0.15 l3=0.15 perp=85.58778125415155\n"
     ]
    }
   ],
   "source": [
    "l1 = 0.7;l2 =0.15;l3 =0.15\n",
    "perp = perplexity(test, l1, l2, l3, t)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124e37d",
   "metadata": {},
   "source": [
    "Como podemos ver sobre el conjunto de test también se obtiene una perplejidad muy buena, ya que es bajo a comparación de las demás, por lo que dichos lambda son una buena elección para nuestro modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca2777",
   "metadata": {},
   "source": [
    "# 3. Generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5769ad",
   "metadata": {},
   "source": [
    "Para esta parte reentrenará su modelo de lenguaje interpolado para aprender los valores λ:\n",
    "\n",
    "P̂(wn|wn−2wn−1) = λ1P(wn|wn−2wn−1) + λ2P(wn|wn−1) + λ3P(wn)\n",
    "\n",
    "Realice las siguientes actividades:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba381a",
   "metadata": {},
   "source": [
    "1. Proponga una estrategia con base en Expectation Maximization (investigue porsu cuenta sobre EM) para encontrar buenos valores de interpolación en P̂ usando todoel dataset de agresividad (Se adjunta un material de apoyo). Para ello experimente conel modelo en particiones estratificadas de 80%, 10% y 10% para entrenar (train), ajustarparámetros (val) y probar (test) respectivamente. 1 Muestre como bajan las perplejidadesen 5 iteraciones que usted elija (de todas las que sean necesarias de acuerdo a su EM) envalidación, y pruebe una vez en test. Sino logra hacer este punto, haga los siguientes doscon el modelo de lenguaje con algunos λ fijos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fc31a",
   "metadata": {},
   "source": [
    "Para este punto, como nos pide trabajar con el mismo conjunto de tweets vamos a utilizar los conjuntos de entrenamientos, validación y testeo que ya teníamos procesados y para los cuales tenemos toda su información y métricas necesarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a5e388ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_p_ngram(words, n):\n",
    "    if n>3: \n",
    "        n=3\n",
    "    if n == 1:\n",
    "        return P_uni[words[-1]]\n",
    "    if n == 2:\n",
    "        return P_bigr((words[-2],words[-1]), freqBigr, freqUni,cond=True)\n",
    "    if n == 3:\n",
    "        return P_trigr((words[-3],words[-2],words[-1]), freqTrigr, freqBigr, freqUni, cond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "630e039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_estimate_lambda(words, iter, l1_0, l2_0, l3_0, s):\n",
    "    # Punto inicial \n",
    "    l = np.array([l1_0, l2_0, l3_0])\n",
    "\n",
    "    M = len(words)   \n",
    "    \n",
    "    q = np.zeros(3, dtype =float)\n",
    "    for i in range(iter):\n",
    "        # E step\n",
    "        for m in range(2,M):\n",
    "            for z in range(3):\n",
    "                q[z] = cond_p_ngram(words[m-2:m+1], z+1) * l[z]\n",
    "            q = q/sum(q)\n",
    "            # Conituous M step\n",
    "            for z in range(3):\n",
    "                l[z] += q[z]\n",
    "        l=l/M\n",
    "        #print(i)\n",
    "        #print(l)\n",
    "\n",
    "        if(i % int(iter/10) ==0 or i==iter-1):  \n",
    "            perp = perplexity(words, l[0], l[1], l[2], s)\n",
    "            print(i, l, \"    perplexity:\", perp)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f176438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [8.24321293e-01 1.75480843e-01 1.20096960e-04]     perplexity: 78.1490959001637\n",
      "5 [8.45640464e-01 1.54281763e-01 1.13940609e-21]     perplexity: 78.08864173968355\n",
      "10 [8.45640997e-01 1.54281231e-01 1.11284437e-38]     perplexity: 78.08864090712801\n",
      "15 [8.45640997e-01 1.54281231e-01 1.08690271e-55]     perplexity: 78.0886409071086\n",
      "20 [8.45640997e-01 1.54281231e-01 1.06156577e-72]     perplexity: 78.0886409071086\n",
      "25 [8.45640997e-01 1.54281231e-01 1.03681947e-89]     perplexity: 78.0886409071086\n",
      "30 [8.45640997e-001 1.54281231e-001 1.01265003e-106]     perplexity: 78.0886409071086\n",
      "35 [8.45640997e-001 1.54281231e-001 9.89044005e-124]     perplexity: 78.0886409071086\n",
      "40 [8.45640997e-001 1.54281231e-001 9.65988265e-141]     perplexity: 78.0886409071086\n",
      "45 [8.45640997e-001 1.54281231e-001 9.43469981e-158]     perplexity: 78.0886409071086\n",
      "49 [8.45640997e-001 1.54281231e-001 2.32558959e-171]     perplexity: 78.0886409071086\n"
     ]
    }
   ],
   "source": [
    "l = EM_estimate_lambda(validation, 50, 1/3, 1/3, 1/3, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65798aa9",
   "metadata": {},
   "source": [
    "Probando con el Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "df6ac297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity on test data: 76.78595250067892\n"
     ]
    }
   ],
   "source": [
    "perp = perplexity(test, l[0], l[1], l[2], t)\n",
    "print(\"perplexity on test data:\" , perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff4414",
   "metadata": {},
   "source": [
    "Como podemos notar, el algoritmo basado en EM convergió a valores de lambdas para los cuales la perplejidad es más baja que la que habíamos escogido en el problema anterior. Revisando nuevamente los valores de perplejidad obtenidos de manera experimental podemos recordar que los más bajos se encontraban entre 70 y 71, por lo que un valor de 76 sería aún mejor que el de 85 obtenido anteriormente, por ser más bajo, y aún bueno en el sentido de no llegar al sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70787e7",
   "metadata": {},
   "source": [
    "2. Haga una función \"tuitear\" con base en su modelo de lenguaje P̂ del último punto.\n",
    "El modelo deberá poder parar automáticamente cuando genere el símbolo de terminación\n",
    "de tuit al final (e.g., \"</s>\"), o 50 palabras. Proponga algo para que en los últimos tokens\n",
    "sea más probable generar el token \"</s>\". Muestre al menos cinco ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b02412",
   "metadata": {},
   "source": [
    "Función para generar tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0091160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_next(wk, wj, avoid, l, probfin):\n",
    "    next = []\n",
    "    for tg in freqTrigr.keys():\n",
    "        if tg[:-1]==(wk, wj) and not tg[-1] in avoid:\n",
    "            p = interpolated_p((wk, wj,tg[-1]), l[0], l[1], l[2])\n",
    "            p = p*probfin if tg[-1]=='</s>' else p\n",
    "            next.append((p, tg[-1]))     \n",
    "    return next\n",
    "            \n",
    "    \n",
    "def tuitear(num_w, l, r, s):\n",
    "    wj = '<s>'\n",
    "    wk = '<s>'\n",
    "    tweet = [wj]\n",
    "    avoid = ['<s>', '<unk>']\n",
    "    \n",
    "    random.seed(s)\n",
    "    for i in range(num_w):\n",
    "        next = generate_next(wk, wj, avoid, l, num_w/(i+1))\n",
    "        if next:\n",
    "            next = sorted(next, reverse = True)[:r] if not wj=='<s>' else next\n",
    "            w = next[random.randint(0, len(next)-1)]\n",
    "            w = w[1]\n",
    "            tweet.append(w)\n",
    "            if w == '</s>':\n",
    "                return tweet\n",
    "        else:\n",
    "            next = [(P_bigr((wj,bg[-1]), freqBigr, freqUni,cond=True),bg[-1])\\\n",
    "                    for bg in freqBigr.keys()\\\n",
    "                    if bg[-2]==wj and not bg[-1] in avoid]\n",
    "            if next:\n",
    "                next = sorted(next, reverse = True)[:r] if not wj=='<s>' else next\n",
    "                w = next[random.randint(0, len(next)-1)]\n",
    "                w = w[1]\n",
    "                tweet.append(w)\n",
    "                if w == '</s>':\n",
    "                    return tweet\n",
    "        wk = wj\n",
    "        wj = tweet[-1]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33eecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> #pontelaverde .. a ver putos yo ! - no me a dado mas fuerte a ese maricon ... méxico tiene un nombre joto en sus putas se dio cuenta . 😂 </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d112b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> mujeres : 1 . ¿ a ti que te voy a pinche rodilla y que de la loca que se me para la comunidad lgbt . puras putas pendejadas </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "319b0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> girardi es la de tu madre y que de vez en cuando había visita en la que no ! a quien se la madre . no se me hace ver que se que putas . ! jajaja </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c1ca78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> guapuras mañana lunes a partir de las de jenny ya se es la de tu puta y vaciarme en tu vida se resume a estar en la @usuario para soltar a sus putos de todos los que me no he muerto y tengo los putos . no me a bloqueado\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17264c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> naaa ... cuando ganamos la final como cagan la verga a las que más les gusta . como es la loca y que de de las mujeres no pueden tener hijos </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d14fe",
   "metadata": {},
   "source": [
    "Como podemos notar los tweets generados son bastantes buenos dado que es un modelo n-gramas, algunos cuentan con cierta coherencia como se esperaba, esto es signo de un buen modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de4934",
   "metadata": {},
   "source": [
    "3. Use la intuición que ha ganado en esta tarea y los datos de las mañaneras para\n",
    "entrenar un modelo de lenguaje AMLO. Haga una un función \"dar_conferencia()\". Generé\n",
    "un discurso de 300 palabras y detenga al modelo de forma abrupta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5e329efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las mañaneras que recolectamos en la práctica 1\n",
    "\n",
    "import glob\n",
    "\n",
    "str_amlo = \"\"\n",
    "\n",
    "for d in glob.glob(\"estenograficas_limpias_por_fecha/*\"):\n",
    "    with open (d, \"r\",encoding=\"utf-8\") as file:\n",
    "        t_conferencia = file.read().replace(\"\\n\", \" \").lower()\n",
    "    str_amlo += t_conferencia\n",
    "    \n",
    "str_amlo = str_amlo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ec93166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_uni = {}\n",
    "N = len(str_amlo)\n",
    "freqUni = nltk.FreqDist(str_amlo)\n",
    "len_V = len(freqUni)\n",
    "for word in freqUni:\n",
    "    P_uni[word] = (freqUni[word]+1) / (N+len_V)\n",
    "    \n",
    "bigrams = [(item[0],item[1]) for item in nltk.bigrams(str_amlo)]\n",
    "freqBigr = Counter(bigrams)\n",
    "\n",
    "trigrams = [(item[0],item[1],item[2]) for item in nltk.trigrams(str_amlo)]\n",
    "freqTrigr = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb51b85",
   "metadata": {},
   "source": [
    "Entrenamos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2aa8f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [5.33509228e-01 4.66490603e-01 6.98296002e-08]     perplexity: 107.35717488045842\n",
      "1 [5.33534596e-01 4.66465314e-01 1.60742630e-14]     perplexity: 107.35715565754903\n",
      "2 [5.33534600e-01 4.66465310e-01 3.70018801e-21]     perplexity: 107.35715565660263\n",
      "3 [5.33534600e-01 4.66465310e-01 8.51758572e-28]     perplexity: 107.35715565659874\n",
      "4 [5.33534600e-01 4.66465310e-01 1.96069136e-34]     perplexity: 107.35715565659874\n",
      "5 [5.33534600e-01 4.66465310e-01 4.51338059e-41]     perplexity: 107.35715565659874\n",
      "6 [5.33534600e-01 4.66465310e-01 1.03895008e-47]     perplexity: 107.35715565659874\n",
      "7 [5.3353460e-01 4.6646531e-01 2.3915937e-54]     perplexity: 107.35715565659874\n",
      "8 [5.33534600e-01 4.66465310e-01 5.50528901e-61]     perplexity: 107.35715565659874\n",
      "9 [5.33534600e-01 4.66465310e-01 1.26728077e-67]     perplexity: 107.35715565659874\n"
     ]
    }
   ],
   "source": [
    "l = EM_estimate_lambda(str_amlo, 10, 0.3, 0.3, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "78bbdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity on test data: 107.35715565659874\n"
     ]
    }
   ],
   "source": [
    "perp = perplexity(str_amlo, l[0],l[1],l[2], 0)\n",
    "print(\"perplexity on test data:\" , perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ac61",
   "metadata": {},
   "source": [
    "Funciones para generar la conferencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "08c8f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_amlo(wk, wj, l):\n",
    "    next = []\n",
    "    for tg in freqTrigr.keys():\n",
    "        if tg[:-1]==(wk, wj):\n",
    "            p = interpolated_p((wk, wj,tg[-1]), l[0], l[1], l[2])\n",
    "            next.append((p, tg[-1]))     \n",
    "    return next\n",
    "            \n",
    "def gen_amlo(w0, w1, num_w, l, r, s):\n",
    "    wk = w0\n",
    "    wj = w1\n",
    "    txt = [wk , wj]\n",
    "    \n",
    "    random.seed(s)\n",
    "    for i in range(num_w):\n",
    "        next = generate_next_amlo(wk, wj, l)\n",
    "        if next:\n",
    "            next = sorted(next, reverse = True)[:r]\n",
    "            w = next[random.randint(0, len(next)-1)]\n",
    "            w = w[1]\n",
    "            txt.append(w)\n",
    "        else:\n",
    "            next = [ (P_bigr((wj,bg[-1]), freqBigr, freqUni,cond=True),bg[-1])\\\n",
    "                    for bg in freqBigr.keys()\\\n",
    "                      if bg[-2]==wj]\n",
    "            if next:\n",
    "                next = sorted(next, reverse = True)[:r]\n",
    "                w = next[random.randint(0, len(next)-1)]\n",
    "                w = w[1]\n",
    "                txt.append(w)\n",
    "        wk = wj\n",
    "        wj = txt[-1]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d59cc834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola ciudadanos están conformes con nada. por eso, que en esta su patria y de no están al alza, lo cual es muy difícil con un programa lo estamos llevando la fiscalía, en este que son y los estados no vamos tener este apoyo del presidente lo respeto a un precio del diésel, pero ya un proceso ya sea los cárteles controlan el gas, pero no de la guardia y para una serie de… presidente andrés lópez obrador es trabajar en las acciones al territorio y es en un buen año 2020 al 2022. el secuestro, a pesar desde que está un tema en el estado es donde se en encontró un déficit, tanto en estados para el día y a ver en una también de la que a las autoridades de lo mismo con mis dos papás fueron vacunados, la mayor atención y lo es porque los derechos más allá que iban tan rápido si me está hablando y nos han entregado lo mejor la fiscalía con los no conservadores, demandando hasta en estos que usted las pruebas con un proceso por este plan y de una persona por parte para dar las condiciones que estamos con mucho más un acuerdo y ya el presidente del gobierno no es el pueblo y ya y no con una gente no haya el tiempo que hay de los derechos que tienen de que a más del programa los periodistas. la mayoría los síntomas y hacer el primer presidente afromexicano, quien nos decía que de méxico, la defensa a su caso los niños que las de esta y otra un cráter, un cráter en la ciudad se sienten o se lo he dicho una fecha nos informó ayer relaciones y tenemos a estos los que está con respecto al presidente lo comentaba de un\n"
     ]
    }
   ],
   "source": [
    "amlo = gen_amlo('hola', 'ciudadanos', 300, l, 15, random.random())\n",
    "amlo = ' '.join(amlo)\n",
    "print(amlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a63ae",
   "metadata": {},
   "source": [
    "El modelo de generación de discursos de amlo se ve que trabaja muy bien aún cuando usamos algo muy básico como los n-gramas. Esto demuestra el poder de un modelo que aunque es sencillo puede llegar a funcionar muy bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48663a71",
   "metadata": {},
   "source": [
    "4. Calcule el estimado de cada uno sus modelos de lenguaje (el de tuits y el de amlo)\n",
    "para las frases: \"sino gano me voy a la chingada\", \"ya se va a acabar la corrupción\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "02ba0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = [\"si\",\"no\",\"gano\",\"me\",\"voy\",\"a\",\"la\",\"chingada\"]\n",
    "str2 = [\"ya\",\"se\",\"va\",\"a\",\"acabar\",\"la\",\"corrupción\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390efac4",
   "metadata": {},
   "source": [
    "Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "923431f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_t = [8.45640997e-001,1.54281231e-001,2.32558959e-171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8615676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  1.9770300041463435e-16\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str1[i-2],str1[i-1],str1[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a22f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  3.2885963171193507e-15\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str2[i-2],str2[i-1],str2[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str2))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e7acf",
   "metadata": {},
   "source": [
    "Modelo de AMLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = math.prod([interpolated_p((str1[i-2],str1[i-1],str1[i]),l[0],l[1],l[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b577f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  3.7097640894512125e-12\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str2[i-2],str2[i-1],str2[i]),l[0],l[1],l[2]) for i in range(2,len(str2))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d9862",
   "metadata": {},
   "source": [
    "Simplemente utilizamos los modelos generados anteriormente para probabarlos con nuevas frases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edb0c6",
   "metadata": {},
   "source": [
    "5. Para cada oración del punto anterior, haga todas las permutaciones posibles.\n",
    "Calcule su probabilidad a cada nueva frase y muestre el top 3 mas probable y el top 3 menos probable (para ambos modelos de lenguaje). Proponga una frase más y haga lo\n",
    "mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "987b10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "str1_all = list(itertools.permutations(str1)) \n",
    "str2_all = list(itertools.permutations(str2)) \n",
    "str3 = [\"le\",\"mandamos\",\"un\",\"saludo\",\"a\",\"la\",\"mamá\",\"del\",\"niño\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b945c",
   "metadata": {},
   "source": [
    "Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fa73a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str1_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]    \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "77b68f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.5059032118271946e-13,\n",
       "  ('chingada', 'gano', 'si', 'no', 'me', 'voy', 'a', 'la')),\n",
       " (3.5058285650169387e-13,\n",
       "  ('gano', 'chingada', 'si', 'no', 'me', 'voy', 'a', 'la')),\n",
       " (3.250196286423799e-13,\n",
       "  ('gano', 'chingada', 'no', 'me', 'voy', 'a', 'la', 'si'))]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "77fdf714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.104359258638601e-18,\n",
       "  ('la', 'a', 'gano', 'no', 'chingada', 'voy', 'me', 'si')),\n",
       " (9.105177272879079e-18,\n",
       "  ('la', 'a', 'gano', 'voy', 'no', 'chingada', 'me', 'si')),\n",
       " (9.116838762985829e-18,\n",
       "  ('la', 'a', 'gano', 'me', 'no', 'chingada', 'voy', 'si'))]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1acff912",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str2_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]    \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "09b62545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.233291494329925e-11,\n",
       "  ('acabar', 'corrupción', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.2332902222389657e-11,\n",
       "  ('corrupción', 'acabar', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.160360530234272e-11,\n",
       "  ('acabar', 'corrupción', 'a', 'la', 'ya', 'se', 'va'))]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9d55c8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.6284439153839253e-16,\n",
       "  ('la', 'a', 'corrupción', 'va', 'se', 'acabar', 'ya')),\n",
       " (1.6324001928727816e-16,\n",
       "  ('la', 'a', 'corrupción', 'se', 'acabar', 'va', 'ya')),\n",
       " (1.6337257321296207e-16,\n",
       "  ('la', 'a', 'corrupción', 'va', 'se', 'ya', 'acabar'))]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "50d187fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  1.3132416497093299e-16\n"
     ]
    }
   ],
   "source": [
    "#Nueva oración dada por mi\n",
    "p = math.prod([interpolated_p((str3[i-2],str3[i-1],str3[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afa60e",
   "metadata": {},
   "source": [
    "Modelo de AMLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fc337809",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str2_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l[0],l[1],l[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]\n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "86a4c754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.4757653325433096e-09,\n",
       "  ('acabar', 'corrupción', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (2.4605909572043068e-09,\n",
       "  ('corrupción', 'acabar', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.6789815745280819e-09,\n",
       "  ('acabar', 'ya', 'se', 'va', 'a', 'la', 'corrupción'))]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "af85d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.2435644955463123e-16,\n",
       "  ('a', 'la', 'acabar', 'va', 'se', 'corrupción', 'ya')),\n",
       " (2.2516676044018094e-16,\n",
       "  ('a', 'la', 'acabar', 'va', 'se', 'ya', 'corrupción')),\n",
       " (2.267159067556165e-16,\n",
       "  ('a', 'la', 'acabar', 'ya', 'corrupción', 'va', 'se'))]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc070644",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str1_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l[0],l[1],l[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]   \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9b71a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['le', 'mandamos', 'un', 'saludo', 'a', 'la', 'mamá', 'del', 'niño']\n",
      "Probabilidad:  3.3470719702831416e-16\n"
     ]
    }
   ],
   "source": [
    "#Nueva oración dada por mi\n",
    "p = math.prod([interpolated_p((str3[i-2],str3[i-1],str3[i]),l[0],l[1],l[2]) for i in range(2,len(str1))])\n",
    "print(str3)\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a11fda",
   "metadata": {},
   "source": [
    "Este punto también es para evaluar los modelos mediante las permutaciones de las oraciones y la tarea es determinar cual es una oración más probable de ser correcta. Los resultados de las top3 fueron buenos, ya que son oraciones con sentido, mientras que las 3 menores fueron lo esperado, oraciones que no tienen sentido. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e00a1b",
   "metadata": {},
   "source": [
    "# (Opcional) El ahorcado (10pts) acumulables solo para tareas: e.g.; esta tarea puede llegar a valer 110/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ec804",
   "metadata": {},
   "source": [
    "Para esta parte estudie y comprenda el funcionamiento de la estrategia propuesta por\n",
    "Norvig http://norvig.com/spell-correct.html. Siéntete libre de adaptar y/o extender parcial o\n",
    "totalmente el código de Norvig para esta tarea.\n",
    "Diseñe una función que sea capaz de encontrar los caracteres faltantes de una palabra. Para\n",
    "ello proponga una adaptación simple de la estrategia de corrección ortográfica propuesta por\n",
    "Norvig. La función de el ahorcado debe poder tratar con hasta 4 caracteres desconocidos en\n",
    "palabras de longitud arbitraria. La función debe trabajar en tiempo razonable (≈ 1 minuto en\n",
    "una laptop o menos). La función debe trabajar como sigue con 10 ejemplos:\n",
    "\n",
    "hangman ( \" pe_p_e \" )\n",
    "’ people ’\n",
    "\n",
    "hangman ( \" phi__sop_y \" )\n",
    "’ philosophy ’\n",
    "\n",
    "hangman ( \" s i _ n i f _ c _ n c _ \" )\n",
    "’ s i g n i f i c a n c e ’\n",
    "\n",
    "Puede resolver este punto con una extensión muy simple de la estrategia de Norvig, o alguna\n",
    "forma más eficiente con distancias de edición (e.g., Levenshtein) o de subcadenas (e.g., Karp\n",
    "Rabin, Aho-Corasick, Tries, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f84e1",
   "metadata": {},
   "source": [
    "Importamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa49ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'big (4).txt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pag = 'http://norvig.com/big.txt'\n",
    "pth = ''\n",
    "wget.download(url = url_pag, out = pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e08e5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Función del ahorcado\"\n",
    "\n",
    "def words(text): \n",
    "    #return re.findall(r'\\w+', text.lower())\n",
    "    return re.findall('[^\\d\\W]+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def hangman(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or \n",
    "            known(ahorcado_edit1(word)) or \n",
    "            known(ahorcado_edit2(word)) or \n",
    "            known(ahorcado_edit3(word)) or \n",
    "            known(ahorcado_edit4(word)) or \n",
    "            [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def ahorcado_edit1(word):\n",
    "    \"Función que trata de adivinar una palabras con hasta 4 letras faltantes\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word)) if word[i]=='_']\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    return set(replaces)\n",
    "\n",
    "def ahorcado_edit2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit1(word) for e2 in ahorcado_edit1(e1))\n",
    "\n",
    "def ahorcado_edit3(word): \n",
    "    \"All edits that are 3 edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit2(word) for e2 in ahorcado_edit1(e1))\n",
    "\n",
    "def ahorcado_edit4(word): \n",
    "    \"All edits that are 4 edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit3(word) for e2 in ahorcado_edit1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d54cde",
   "metadata": {},
   "source": [
    "La idea de la función es realizar los splits de las palabras, solamente si se encuentra un espacio vacío. Con dicho espacio solamente se realizará la operación de reemplazo por otra letra. Con esta misma estrategia se buscarán posibles palabras reemplazando hasta 4 veces los espacios vacíos, (fácilmente extendible hasta más letras). Para palabras con más de 1 letra faltante, lo que se hace es realizar los posibles reemplazos con n-1 letras faltantes y luego hacer otro reemplazo extra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92b6bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spelling'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman('sp_l_i__')\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f18c3f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'people'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman ( \"pe_p_e\" )\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3b4d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 0.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'philosophy'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"phi__sop_y\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4785b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'significance'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"si_nif_c_nc_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ee021766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"he__o\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "df32d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'refrigerator'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"refr_g_r_t_r\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "feb11405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'essential'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"e_se__ia_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f79f05b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'languages'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"l__gu_ge_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a898590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'denmark'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"d__ma__\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0765050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la solución: 4.07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'europe'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"eu____\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la solución: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ec8e7",
   "metadata": {},
   "source": [
    "Comente brevemente como integraría un modelo de lenguaje con el modelo de Norvig\n",
    "para tratar de resolver errores gramaticales de más alto nivel, o errores dónde el error sea una\n",
    "palabra que si está en el diccionario, por ejemplo: \"In the science off Maths ...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21b3d5",
   "metadata": {},
   "source": [
    "Para abordar este problema, se podría utilizar el modelo de lenguaje para generar una lista de posibles correcciones para la oración con errores. A continuación, se podría utilizar el modelo de Norvig para determinar la probabilidad de cada corrección y elegir la más probable.\n",
    "\n",
    "Una forma de hacer esto sería:\n",
    "\n",
    "Utilizar el modelo de lenguaje para generar una lista de posibles correcciones para la oración con errores. Esto se puede hacer utilizando técnicas de corrección de errores basadas en modelos de lenguaje, como la corrección de errores basada en estadísticas o la corrección de errores basada en redes neuronales.\n",
    "\n",
    "Utilizar el modelo de Norvig para determinar la probabilidad de cada corrección. El modelo de Norvig utiliza técnicas de procesamiento de lenguaje natural para determinar la probabilidad de una palabra dada en un contexto determinado. En este caso, se podría utilizar el modelo de Norvig para determinar la probabilidad de cada posible corrección en el contexto de la oración con errores.\n",
    "\n",
    "Elegir la corrección más probable. Una vez que se han determinado las probabilidades de cada posible corrección utilizando el modelo de Norvig, se podría elegir la corrección más probable como la corrección sugerida para la oración con errores.\n",
    "\n",
    "En el ejemplo dado, \"In the science off Maths ...\" se podría identificar que \"off\" es una palabra incorrecta y proponer como posible corrección la palabra \"of\". A continuación, el modelo de Norvig podría determinar la probabilidad de que \"of\" sea la palabra correcta en el contexto de la oración, teniendo en cuenta la estructura gramatical y semántica de la oración. Si \"of\" tiene una probabilidad alta, entonces se podría elegir como la corrección sugerida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
