{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0e4099",
   "metadata": {},
   "source": [
    "# Ernesto Antonio Retes Ram√≠rez \n",
    "\n",
    "# Procesamiento de Lenguaje Natural \n",
    "\n",
    "# Tarea 4: Statistical Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaee2fd",
   "metadata": {},
   "source": [
    "# AYUDA\n",
    "\n",
    "Mi compa√±ero Daniel me ayud√≥ en el punto 2.1 para la creaci√≥n del corpus y del vocabulario. Me ayud√≥ de la siguiente manera: yo ten√≠a duda sobre la asignaci√≥n de $<s>$ y $<s>$, ya que no ten√≠a claro cuantos EOS ten√≠a que agregar. √âl me explic√≥ que era necesario agregar un EOS para distinguir entre oraciones, pero que con uno solo bastaba, no era como en el caso de BOS, ya que al estar tomando los dos elementos por detr√°s de ti en los modelos de trigramas, no necesita agregar m√°s para calcular todas las probabilidades. Tambi√©n me dijo que, desde su punto de vista, podr√≠a ser ventajoso agregar dos BOS a cada tweet y ese corpus utilizar para todos los modelos, ya que de cierta forma queremos trabajar sobre el mismo conjunto de datos para poder medirlo con la perplejidad y compararlos.\n",
    "\n",
    "\n",
    "Por otro lado, ayud√© a mi compa√±ero Daniel con respecto al punto 2.3, ya que estaba utilizando la definici√≥n exacta de perplejidad la cual da unos ciertos problemas num√©ricos. Mi ayuda fue mostrarle y explicarle otro forma de clacular la perplejidad utilizando la entrop√≠a, que es un m√©todo el cual explican en el capitulo de Dan como tema avanzado en el final. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056746e",
   "metadata": {},
   "source": [
    "# 2. Modelo de Lenguaje y Evaluaci√≥n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24601a9",
   "metadata": {},
   "source": [
    "1. Preprocese todos los tuits de agresividad (positivos y negativos) seg√∫n su intuici√≥n para construir un buen corpus para un modelo de lenguaje (e.g., solo palabras en min√∫scula, etc.). Agregue tokens especiales de $<s>$ y $</s>$ seg√∫n usted considere (e.g., al inicio y final de cada tuit). Defina su vocabulario y enmascare con <unk> toda palabra que no est√© en su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3335ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wget\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2719c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus,path_truth):\n",
    "    tr_text = []\n",
    "    tr_y = []\n",
    "    \n",
    "    with open(path_corpus,\"r\",encoding=\"utf-8\") as f_corpus, open(path_truth,\"r\",encoding=\"utf-8\") as f_truth:\n",
    "        for twitt in f_corpus:\n",
    "            tr_text += [twitt]\n",
    "        for label in f_truth:\n",
    "            tr_y += [label]\n",
    "    return tr_text,tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d35c380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el conjunto de datos \n",
    "tr_txt, tr_y = get_texts_from_file(\"mex_train.txt\",\"mex_train_labels.txt\")\n",
    "test_txt, test_y = get_texts_from_file(\"mex_val.txt\",\"mex_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "38dbc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, val_txt = train_test_split(tr_txt, test_size=616, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2eb766b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "68d59bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos minuscula el texto y agregamos inicio(<s>) y final(</s>) de tweet dependiendo el caso\n",
    "corpus = []\n",
    "\n",
    "for doc in tr_txt:\n",
    "    corpus += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "fdist1 = nltk.FreqDist(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "77fe6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key],key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f4e69216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos nuestros vocabularios con las 10000 palabras m√°s frecuentes\n",
    "Vocabulary = sortFreqDict(fdist1)\n",
    "Vocabulary = Vocabulary[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5ab7932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indices = dict()\n",
    "cont = 0 \n",
    "\n",
    "for weight, word in Vocabulary:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1ad444d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado nuestro vocabulario, las palabras que no est√°n en √©l las cambiamos por \"unk\"\n",
    "train = [ w if w in dict_indices else '<unk>' for w in corpus]\n",
    "N = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "11e6a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulario con unk\n",
    "fdist2 = nltk.FreqDist(train)\n",
    "V = sortFreqDict(fdist2)\n",
    "\n",
    "dict_ind = dict()\n",
    "cont = 0 \n",
    "\n",
    "for weight, word in V:\n",
    "    dict_ind[word] = cont\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f724546",
   "metadata": {},
   "source": [
    "El corpus que creamos llamdo train lo hice de la siguiente forma. A cada tweet le agreg√© dos $<s>$ al inicio y un $</s>$ al final. Esto ya que queremos trabajar hasta con trigramas. Tokenize los tweets y form√© mi vocabulario con las 10000 palabras m√°s frecuentes. Finalmente enmascar√© las palabras que no pertenecen al corpus con el caracter $<unk>$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc51273",
   "metadata": {},
   "source": [
    "2. Entrene tres modelos de lenguaje sobre todos los tuits: Unigramas(wn1), bigramas(wn1),trigramas(wn1). Para cada uno proporcione una interfaz (funci√≥n) sencilla para Pn‚àígrama(wn1)y Pn‚àígrama(wn1|wn‚àí1n‚àíN+1). Los modelos deben tener una estrategia com√∫n para lidiar consecuencias no vistas. Puede optar por un suavizamiento Laplace o un Good-Turingdiscounting. Muestre un par de ejemplos de como funciona, al menos uno con unapalabra fuera del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfe490",
   "metadata": {},
   "source": [
    "UNIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "da68d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funci√≥n para calcular la probabilidad de una palabra    \n",
    "\n",
    "P_uni = {}\n",
    "N = len(train)\n",
    "len_V = len(V)\n",
    "for frec, word in V:\n",
    "    P_uni[word] = (frec+1) / (N+len_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4b66a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contiene las frecuencias de cada palabra\n",
    "freqUni = Counter(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2b957",
   "metadata": {},
   "source": [
    "Probando algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c48608e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008255638314495547"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"madre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5984374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08556869281386183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"<s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6941edd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023048075420594824"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5b806dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012587461152490582"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_uni[\"puto\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423d9ff",
   "metadata": {},
   "source": [
    "BIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "82a0f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos nuestros bigramas\n",
    "bigrams = [(item[0],item[1]) for item in nltk.bigrams(train)]\n",
    "freqBigr = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b805af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_bigr(bigram, freq={}, freqU={}, cond=False):\n",
    "    if cond:\n",
    "        if bigram not in freq:\n",
    "            return 1 / (freqU[bigram[0]]+len_V)\n",
    "        return (freq[bigram]+1) / (freqU[bigram[0]]+len_V)\n",
    "    \n",
    "    else:\n",
    "        ans = np.log(P_uni[bigram[1]])\n",
    "        ans += np.log((freq[bigram]+1) / (freqU[bigram[0]]+len_V))\n",
    "        return  np.exp(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98b353a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('<s>', '<s>')\n",
      "0.021240272290855868\n",
      "\n",
      "P( <s> | <s> )\n",
      "0.2482248073727149\n"
     ]
    }
   ],
   "source": [
    "bigram = bigrams[0]\n",
    "print('P', bigram)\n",
    "print(P_bigr(bigram, freqBigr, freqUni))\n",
    "print('\\nP(', bigram[1],'|',bigram[0],')')\n",
    "print(P_bigr(bigram, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a21c7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('</s>', '<s>')\n",
      "0.028245864973321128\n",
      "\n",
      "P( <s> | </s> )\n",
      "0.3300957867238261\n"
     ]
    }
   ],
   "source": [
    "bigram = bigrams[23]\n",
    "print('P', bigram)\n",
    "print(P_bigr(bigram, freqBigr, freqUni))\n",
    "print('\\nP(', bigram[1],'|',bigram[0],')')\n",
    "print(P_bigr(bigram, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426b9fb",
   "metadata": {},
   "source": [
    "Notemos que de tener un signo de final siga uno de inicio es un hecho muy probable, tomando en cuenta que hemos hecho un\n",
    "suavizamiento laplaciano donde toda la masa de probabilidad se ha movido. La probabilidad no es cerca a 1 porque hemos movido toda la masa de probabilidad con el suavizamiento laplaciano. Pero a√∫n as√≠ es muy alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3e448",
   "metadata": {},
   "source": [
    "TRIGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6c012e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [(item[0],item[1],item[2]) for item in nltk.trigrams(train)]\n",
    "freqTrigr = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "70583f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_trigr(trigram, freq={}, freqB={}, freqU={}, cond=False):\n",
    "    lenVB = len(freqB)\n",
    "    if cond:\n",
    "        if trigram not in freq:\n",
    "            return 1 / (freqB[(trigram[0],trigram[1])] + lenVB)\n",
    "        return (freq[trigram]+1) / (freqB[(trigram[0],trigram[1])] + lenVB)\n",
    "    \n",
    "    else:\n",
    "        ans = np.log(P_uni[trigram[2]])\n",
    "        ans += np.log(P_bigr((trigram[1],trigram[2]), freqB, freqU, True))\n",
    "        ans += np.log((freq[trigram]+1) / (freqB[(trigram[0],trigram[1])] + lenVB))\n",
    "        return  np.exp(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dafcf0",
   "metadata": {},
   "source": [
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "828f7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('<s>', 'vamos', 'a')\n",
      "2.820764452218357e-09\n",
      "\n",
      "P( a | <s> vamos )\n",
      "8.213383708753413e-05\n"
     ]
    }
   ],
   "source": [
    "trigram = trigrams[1]\n",
    "print('P', trigram)\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni))\n",
    "print('\\nP(', trigram[2],'|',trigram[0],trigram[1],')')\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40c6441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P ('</s>', '<s>', '<s>')\n",
      "0.0019519629615347169\n",
      "\n",
      "P( <s> | </s> <s> )\n",
      "0.09189914963449201\n"
     ]
    }
   ],
   "source": [
    "trigram = trigrams[23]\n",
    "print('P', trigram)\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni))\n",
    "print('\\nP(', trigram[2],'|',trigram[0],trigram[1],')')\n",
    "print(P_trigr(trigram, freqTrigr, freqBigr, freqUni, cond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ac3c3",
   "metadata": {},
   "source": [
    "Como se esperaba el trigrama de un signo final con dos iniciales es uno que esperar√≠amos tenga probabilidad alta ya que se repite much√≠simo, al nosotros agregarlo a cada tweet. Otro trigrama como el primero es poco com√∫n por eso tiene una probabilidad muy baja aunque como podemos ver no es cero. Por lo que en general, los resultados de cada uno de los modelos son consistentes con lo esperado, y podr√≠amos decir son buenos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f5fa6",
   "metadata": {},
   "source": [
    "3. Construya un modelo interpolado con valores Œª fijos:PÃÇ(wn|wn‚àí2wn‚àí1) = Œª1P(wn|wn‚àí2wn‚àí1) + Œª2P(wn|wn‚àí1) + Œª3P(wn)Para ello experimente con el modelo en particiones estratificadas de 80%, 10% y 10%\n",
    "para entrenar (train), ajuste de par√°metros (val) y prueba (test) respectivamente. Muestrecomo bajan o suben las perplejidades en validaci√≥n, finalmente pruebe una vez entest. Para esto puede explorar algunos valores ‚ÉóŒª y elija el mejor. Pruebe las siguientes:[1/3, 1/3, 1/3],[.4, .4, .2],[.2, .4, .4],[.5, .4, .1] y [.1, .4, .5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2795d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def interpolated_p(trigram, l1, l2, l3):\n",
    "    return l3*P_trigr(trigram, freqTrigr, freqBigr, freqUni,cond=True) + l2*P_bigr((trigram[1],trigram[2]),freqBigr, freqUni,cond=True) + l1*P_uni[trigram[2]]\n",
    "\n",
    "def perplexity(corpus, l1, l2, l3,s):\n",
    "    N = len(corpus) - 2*s\n",
    "    p = 0\n",
    "    \n",
    "    p = sum([np.log(interpolated_p((corpus[i-2],corpus[i-1],corpus[i]),l1,l2,l3)) for i in range(2,len(corpus))])\n",
    "    H = (-1/N)*p\n",
    "    return 2**H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e1a0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamos el conjunto de validaci√≥n \n",
    "validation = []\n",
    "\n",
    "for doc in val_txt:\n",
    "    validation += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "validation = [ w if w in dict_indices else '<unk>' for w in validation]\n",
    "s = len(val_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f3feedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.3333333333333333 l2=0.3333333333333333 l3=0.3333333333333333 perp=110.55313668294157\n",
      "for l1=0.4 l2=0.4 l3=0.2 perp=97.7721684986476\n",
      "for l1=0.2 l2=0.4 l3=0.4 perp=129.78369190056088\n",
      "for l1=0.5 l2=0.4 l3=0.1 perp=88.37834023431512\n",
      "for l1=0.1 l2=0.4 l3=0.5 perp=164.34575664442343\n"
     ]
    }
   ],
   "source": [
    "# Tests 1\n",
    "l1 = 1/3;l2 = 1/3;l3 = 1/3\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.4;l2 = 0.4;l3 =0.2\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.2;l2 =0.4;l3 =0.4\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.5;l2 =0.4;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.1;l2=0.4;l3 =0.5\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5520ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.18 l2=0.8 l3=0.02 perp=106.26929194702721\n",
      "for l1=0.06 l2=0.8 l3=0.14 perp=140.89781629360468\n",
      "for l1=0.05 l2=0.85 l3=0.1 perp=141.9018502613383\n",
      "for l1=0.7 l2=0.15 l3=0.15 perp=87.02942984781916\n",
      "for l1=0.8 l2=0.1 l3=0.1 perp=83.68766447504112\n"
     ]
    }
   ],
   "source": [
    "# Tests 2\n",
    "l1 =0.18;l2=0.8;l3=0.02\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.06;l2 = 0.8;l3 =0.14\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.05;l2 =0.85;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.7;l2 =0.15;l3 =0.15\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2=0.1;l3 =0.1\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44e0dfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.9 l2=0.05 l3=0.05 perp=81.1056816940672\n",
      "for l1=0.8 l2=0.15 l3=0.05 perp=80.79218952940077\n",
      "for l1=0.8 l2=0.05 l3=0.15 perp=87.05767624051929\n",
      "for l1=1 l2=0 l3=0 perp=79.20123264533848\n"
     ]
    }
   ],
   "source": [
    "# Test 3\n",
    "l1 = 0.9;l2 =0.05;l3 =0.05\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2 =0.15;l3 =0.05\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 0.8;l2=0.05;l3 =0.15\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))\n",
    "\n",
    "l1 = 1;l2=0;l3 =0\n",
    "perp = perplexity(validation, l1, l2, l3, s)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908294e0",
   "metadata": {},
   "source": [
    "Vamos a tomar los valores de $\\lambda_1 = 0.7, \\lambda_2 = 0.15, \\lambda_3 = 0.15$, los cuales presentaron un nivel de perplejidad de 87.03 apr√≥ximadamente, el cual a comparaci√≥n de las dem√°s pruebas, es un valor bajo pero sin llegar a ser de los m√°s bajos para evitar el sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae34fad",
   "metadata": {},
   "source": [
    "Finalmente probabmos dichos valores una vez con el conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f704527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamos el conjunto de test\n",
    "test = []\n",
    "\n",
    "for doc in test_txt:\n",
    "    test += [\"<s>\"] + [\"<s>\"] + tokenizer.tokenize(doc) + [\"</s>\"] \n",
    "    \n",
    "test = [ w if w in dict_indices else '<unk>' for w in test]\n",
    "t = len(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4acba65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for l1=0.7 l2=0.15 l3=0.15 perp=85.58778125415155\n"
     ]
    }
   ],
   "source": [
    "l1 = 0.7;l2 =0.15;l3 =0.15\n",
    "perp = perplexity(test, l1, l2, l3, t)\n",
    "print(\"for l1={} l2={} l3={} perp={}\".format(l1, l2, l3, perp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124e37d",
   "metadata": {},
   "source": [
    "Como podemos ver sobre el conjunto de test tambi√©n se obtiene una perplejidad muy buena, ya que es bajo a comparaci√≥n de las dem√°s, por lo que dichos lambda son una buena elecci√≥n para nuestro modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca2777",
   "metadata": {},
   "source": [
    "# 3. Generaci√≥n de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5769ad",
   "metadata": {},
   "source": [
    "Para esta parte reentrenar√° su modelo de lenguaje interpolado para aprender los valores Œª:\n",
    "\n",
    "PÃÇ(wn|wn‚àí2wn‚àí1) = Œª1P(wn|wn‚àí2wn‚àí1) + Œª2P(wn|wn‚àí1) + Œª3P(wn)\n",
    "\n",
    "Realice las siguientes actividades:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba381a",
   "metadata": {},
   "source": [
    "1. Proponga una estrategia con base en Expectation Maximization (investigue porsu cuenta sobre EM) para encontrar buenos valores de interpolaci√≥n en PÃÇ usando todoel dataset de agresividad (Se adjunta un material de apoyo). Para ello experimente conel modelo en particiones estratificadas de 80%, 10% y 10% para entrenar (train), ajustarpar√°metros (val) y probar (test) respectivamente. 1 Muestre como bajan las perplejidadesen 5 iteraciones que usted elija (de todas las que sean necesarias de acuerdo a su EM) envalidaci√≥n, y pruebe una vez en test. Sino logra hacer este punto, haga los siguientes doscon el modelo de lenguaje con algunos Œª fijos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fc31a",
   "metadata": {},
   "source": [
    "Para este punto, como nos pide trabajar con el mismo conjunto de tweets vamos a utilizar los conjuntos de entrenamientos, validaci√≥n y testeo que ya ten√≠amos procesados y para los cuales tenemos toda su informaci√≥n y m√©tricas necesarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a5e388ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_p_ngram(words, n):\n",
    "    if n>3: \n",
    "        n=3\n",
    "    if n == 1:\n",
    "        return P_uni[words[-1]]\n",
    "    if n == 2:\n",
    "        return P_bigr((words[-2],words[-1]), freqBigr, freqUni,cond=True)\n",
    "    if n == 3:\n",
    "        return P_trigr((words[-3],words[-2],words[-1]), freqTrigr, freqBigr, freqUni, cond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "630e039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_estimate_lambda(words, iter, l1_0, l2_0, l3_0, s):\n",
    "    # Punto inicial \n",
    "    l = np.array([l1_0, l2_0, l3_0])\n",
    "\n",
    "    M = len(words)   \n",
    "    \n",
    "    q = np.zeros(3, dtype =float)\n",
    "    for i in range(iter):\n",
    "        # E step\n",
    "        for m in range(2,M):\n",
    "            for z in range(3):\n",
    "                q[z] = cond_p_ngram(words[m-2:m+1], z+1) * l[z]\n",
    "            q = q/sum(q)\n",
    "            # Conituous M step\n",
    "            for z in range(3):\n",
    "                l[z] += q[z]\n",
    "        l=l/M\n",
    "        #print(i)\n",
    "        #print(l)\n",
    "\n",
    "        if(i % int(iter/10) ==0 or i==iter-1):  \n",
    "            perp = perplexity(words, l[0], l[1], l[2], s)\n",
    "            print(i, l, \"    perplexity:\", perp)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f176438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [8.24321293e-01 1.75480843e-01 1.20096960e-04]     perplexity: 78.1490959001637\n",
      "5 [8.45640464e-01 1.54281763e-01 1.13940609e-21]     perplexity: 78.08864173968355\n",
      "10 [8.45640997e-01 1.54281231e-01 1.11284437e-38]     perplexity: 78.08864090712801\n",
      "15 [8.45640997e-01 1.54281231e-01 1.08690271e-55]     perplexity: 78.0886409071086\n",
      "20 [8.45640997e-01 1.54281231e-01 1.06156577e-72]     perplexity: 78.0886409071086\n",
      "25 [8.45640997e-01 1.54281231e-01 1.03681947e-89]     perplexity: 78.0886409071086\n",
      "30 [8.45640997e-001 1.54281231e-001 1.01265003e-106]     perplexity: 78.0886409071086\n",
      "35 [8.45640997e-001 1.54281231e-001 9.89044005e-124]     perplexity: 78.0886409071086\n",
      "40 [8.45640997e-001 1.54281231e-001 9.65988265e-141]     perplexity: 78.0886409071086\n",
      "45 [8.45640997e-001 1.54281231e-001 9.43469981e-158]     perplexity: 78.0886409071086\n",
      "49 [8.45640997e-001 1.54281231e-001 2.32558959e-171]     perplexity: 78.0886409071086\n"
     ]
    }
   ],
   "source": [
    "l = EM_estimate_lambda(validation, 50, 1/3, 1/3, 1/3, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65798aa9",
   "metadata": {},
   "source": [
    "Probando con el Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "df6ac297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity on test data: 76.78595250067892\n"
     ]
    }
   ],
   "source": [
    "perp = perplexity(test, l[0], l[1], l[2], t)\n",
    "print(\"perplexity on test data:\" , perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff4414",
   "metadata": {},
   "source": [
    "Como podemos notar, el algoritmo basado en EM convergi√≥ a valores de lambdas para los cuales la perplejidad es m√°s baja que la que hab√≠amos escogido en el problema anterior. Revisando nuevamente los valores de perplejidad obtenidos de manera experimental podemos recordar que los m√°s bajos se encontraban entre 70 y 71, por lo que un valor de 76 ser√≠a a√∫n mejor que el de 85 obtenido anteriormente, por ser m√°s bajo, y a√∫n bueno en el sentido de no llegar al sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70787e7",
   "metadata": {},
   "source": [
    "2. Haga una funci√≥n \"tuitear\" con base en su modelo de lenguaje PÃÇ del √∫ltimo punto.\n",
    "El modelo deber√° poder parar autom√°ticamente cuando genere el s√≠mbolo de terminaci√≥n\n",
    "de tuit al final (e.g., \"</s>\"), o 50 palabras. Proponga algo para que en los √∫ltimos tokens\n",
    "sea m√°s probable generar el token \"</s>\". Muestre al menos cinco ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b02412",
   "metadata": {},
   "source": [
    "Funci√≥n para generar tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0091160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_next(wk, wj, avoid, l, probfin):\n",
    "    next = []\n",
    "    for tg in freqTrigr.keys():\n",
    "        if tg[:-1]==(wk, wj) and not tg[-1] in avoid:\n",
    "            p = interpolated_p((wk, wj,tg[-1]), l[0], l[1], l[2])\n",
    "            p = p*probfin if tg[-1]=='</s>' else p\n",
    "            next.append((p, tg[-1]))     \n",
    "    return next\n",
    "            \n",
    "    \n",
    "def tuitear(num_w, l, r, s):\n",
    "    wj = '<s>'\n",
    "    wk = '<s>'\n",
    "    tweet = [wj]\n",
    "    avoid = ['<s>', '<unk>']\n",
    "    \n",
    "    random.seed(s)\n",
    "    for i in range(num_w):\n",
    "        next = generate_next(wk, wj, avoid, l, num_w/(i+1))\n",
    "        if next:\n",
    "            next = sorted(next, reverse = True)[:r] if not wj=='<s>' else next\n",
    "            w = next[random.randint(0, len(next)-1)]\n",
    "            w = w[1]\n",
    "            tweet.append(w)\n",
    "            if w == '</s>':\n",
    "                return tweet\n",
    "        else:\n",
    "            next = [(P_bigr((wj,bg[-1]), freqBigr, freqUni,cond=True),bg[-1])\\\n",
    "                    for bg in freqBigr.keys()\\\n",
    "                    if bg[-2]==wj and not bg[-1] in avoid]\n",
    "            if next:\n",
    "                next = sorted(next, reverse = True)[:r] if not wj=='<s>' else next\n",
    "                w = next[random.randint(0, len(next)-1)]\n",
    "                w = w[1]\n",
    "                tweet.append(w)\n",
    "                if w == '</s>':\n",
    "                    return tweet\n",
    "        wk = wj\n",
    "        wj = tweet[-1]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33eecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> #pontelaverde .. a ver putos yo ! - no me a dado mas fuerte a ese maricon ... m√©xico tiene un nombre joto en sus putas se dio cuenta . üòÇ </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d112b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> mujeres : 1 . ¬ø a ti que te voy a pinche rodilla y que de la loca que se me para la comunidad lgbt . puras putas pendejadas </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "319b0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> girardi es la de tu madre y que de vez en cuando hab√≠a visita en la que no ! a quien se la madre . no se me hace ver que se que putas . ! jajaja </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c1ca78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> guapuras ma√±ana lunes a partir de las de jenny ya se es la de tu puta y vaciarme en tu vida se resume a estar en la @usuario para soltar a sus putos de todos los que me no he muerto y tengo los putos . no me a bloqueado\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17264c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> naaa ... cuando ganamos la final como cagan la verga a las que m√°s les gusta . como es la loca y que de de las mujeres no pueden tener hijos </s>\n"
     ]
    }
   ],
   "source": [
    "gen_tweet = tuitear(50, l, 5, random.random())\n",
    "gen_tweet = ' '.join(gen_tweet)\n",
    "print(gen_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d14fe",
   "metadata": {},
   "source": [
    "Como podemos notar los tweets generados son bastantes buenos dado que es un modelo n-gramas, algunos cuentan con cierta coherencia como se esperaba, esto es signo de un buen modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de4934",
   "metadata": {},
   "source": [
    "3. Use la intuici√≥n que ha ganado en esta tarea y los datos de las ma√±aneras para\n",
    "entrenar un modelo de lenguaje AMLO. Haga una un funci√≥n \"dar_conferencia()\". Gener√©\n",
    "un discurso de 300 palabras y detenga al modelo de forma abrupta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5e329efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de las ma√±aneras que recolectamos en la pr√°ctica 1\n",
    "\n",
    "import glob\n",
    "\n",
    "str_amlo = \"\"\n",
    "\n",
    "for d in glob.glob(\"estenograficas_limpias_por_fecha/*\"):\n",
    "    with open (d, \"r\",encoding=\"utf-8\") as file:\n",
    "        t_conferencia = file.read().replace(\"\\n\", \" \").lower()\n",
    "    str_amlo += t_conferencia\n",
    "    \n",
    "str_amlo = str_amlo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ec93166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_uni = {}\n",
    "N = len(str_amlo)\n",
    "freqUni = nltk.FreqDist(str_amlo)\n",
    "len_V = len(freqUni)\n",
    "for word in freqUni:\n",
    "    P_uni[word] = (freqUni[word]+1) / (N+len_V)\n",
    "    \n",
    "bigrams = [(item[0],item[1]) for item in nltk.bigrams(str_amlo)]\n",
    "freqBigr = Counter(bigrams)\n",
    "\n",
    "trigrams = [(item[0],item[1],item[2]) for item in nltk.trigrams(str_amlo)]\n",
    "freqTrigr = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb51b85",
   "metadata": {},
   "source": [
    "Entrenamos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2aa8f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [5.33509228e-01 4.66490603e-01 6.98296002e-08]     perplexity: 107.35717488045842\n",
      "1 [5.33534596e-01 4.66465314e-01 1.60742630e-14]     perplexity: 107.35715565754903\n",
      "2 [5.33534600e-01 4.66465310e-01 3.70018801e-21]     perplexity: 107.35715565660263\n",
      "3 [5.33534600e-01 4.66465310e-01 8.51758572e-28]     perplexity: 107.35715565659874\n",
      "4 [5.33534600e-01 4.66465310e-01 1.96069136e-34]     perplexity: 107.35715565659874\n",
      "5 [5.33534600e-01 4.66465310e-01 4.51338059e-41]     perplexity: 107.35715565659874\n",
      "6 [5.33534600e-01 4.66465310e-01 1.03895008e-47]     perplexity: 107.35715565659874\n",
      "7 [5.3353460e-01 4.6646531e-01 2.3915937e-54]     perplexity: 107.35715565659874\n",
      "8 [5.33534600e-01 4.66465310e-01 5.50528901e-61]     perplexity: 107.35715565659874\n",
      "9 [5.33534600e-01 4.66465310e-01 1.26728077e-67]     perplexity: 107.35715565659874\n"
     ]
    }
   ],
   "source": [
    "l = EM_estimate_lambda(str_amlo, 10, 0.3, 0.3, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "78bbdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity on test data: 107.35715565659874\n"
     ]
    }
   ],
   "source": [
    "perp = perplexity(str_amlo, l[0],l[1],l[2], 0)\n",
    "print(\"perplexity on test data:\" , perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ac61",
   "metadata": {},
   "source": [
    "Funciones para generar la conferencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "08c8f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_amlo(wk, wj, l):\n",
    "    next = []\n",
    "    for tg in freqTrigr.keys():\n",
    "        if tg[:-1]==(wk, wj):\n",
    "            p = interpolated_p((wk, wj,tg[-1]), l[0], l[1], l[2])\n",
    "            next.append((p, tg[-1]))     \n",
    "    return next\n",
    "            \n",
    "def gen_amlo(w0, w1, num_w, l, r, s):\n",
    "    wk = w0\n",
    "    wj = w1\n",
    "    txt = [wk , wj]\n",
    "    \n",
    "    random.seed(s)\n",
    "    for i in range(num_w):\n",
    "        next = generate_next_amlo(wk, wj, l)\n",
    "        if next:\n",
    "            next = sorted(next, reverse = True)[:r]\n",
    "            w = next[random.randint(0, len(next)-1)]\n",
    "            w = w[1]\n",
    "            txt.append(w)\n",
    "        else:\n",
    "            next = [ (P_bigr((wj,bg[-1]), freqBigr, freqUni,cond=True),bg[-1])\\\n",
    "                    for bg in freqBigr.keys()\\\n",
    "                      if bg[-2]==wj]\n",
    "            if next:\n",
    "                next = sorted(next, reverse = True)[:r]\n",
    "                w = next[random.randint(0, len(next)-1)]\n",
    "                w = w[1]\n",
    "                txt.append(w)\n",
    "        wk = wj\n",
    "        wj = txt[-1]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d59cc834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola ciudadanos est√°n conformes con nada. por eso, que en esta su patria y de no est√°n al alza, lo cual es muy dif√≠cil con un programa lo estamos llevando la fiscal√≠a, en este que son y los estados no vamos tener este apoyo del presidente lo respeto a un precio del di√©sel, pero ya un proceso ya sea los c√°rteles controlan el gas, pero no de la guardia y para una serie de‚Ä¶ presidente andr√©s l√≥pez obrador es trabajar en las acciones al territorio y es en un buen a√±o 2020 al 2022. el secuestro, a pesar desde que est√° un tema en el estado es donde se en encontr√≥ un d√©ficit, tanto en estados para el d√≠a y a ver en una tambi√©n de la que a las autoridades de lo mismo con mis dos pap√°s fueron vacunados, la mayor atenci√≥n y lo es porque los derechos m√°s all√° que iban tan r√°pido si me est√° hablando y nos han entregado lo mejor la fiscal√≠a con los no conservadores, demandando hasta en estos que usted las pruebas con un proceso por este plan y de una persona por parte para dar las condiciones que estamos con mucho m√°s un acuerdo y ya el presidente del gobierno no es el pueblo y ya y no con una gente no haya el tiempo que hay de los derechos que tienen de que a m√°s del programa los periodistas. la mayor√≠a los s√≠ntomas y hacer el primer presidente afromexicano, quien nos dec√≠a que de m√©xico, la defensa a su caso los ni√±os que las de esta y otra un cr√°ter, un cr√°ter en la ciudad se sienten o se lo he dicho una fecha nos inform√≥ ayer relaciones y tenemos a estos los que est√° con respecto al presidente lo comentaba de un\n"
     ]
    }
   ],
   "source": [
    "amlo = gen_amlo('hola', 'ciudadanos', 300, l, 15, random.random())\n",
    "amlo = ' '.join(amlo)\n",
    "print(amlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a63ae",
   "metadata": {},
   "source": [
    "El modelo de generaci√≥n de discursos de amlo se ve que trabaja muy bien a√∫n cuando usamos algo muy b√°sico como los n-gramas. Esto demuestra el poder de un modelo que aunque es sencillo puede llegar a funcionar muy bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48663a71",
   "metadata": {},
   "source": [
    "4. Calcule el estimado de cada uno sus modelos de lenguaje (el de tuits y el de amlo)\n",
    "para las frases: \"sino gano me voy a la chingada\", \"ya se va a acabar la corrupci√≥n\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "02ba0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = [\"si\",\"no\",\"gano\",\"me\",\"voy\",\"a\",\"la\",\"chingada\"]\n",
    "str2 = [\"ya\",\"se\",\"va\",\"a\",\"acabar\",\"la\",\"corrupci√≥n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390efac4",
   "metadata": {},
   "source": [
    "Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "923431f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_t = [8.45640997e-001,1.54281231e-001,2.32558959e-171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8615676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  1.9770300041463435e-16\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str1[i-2],str1[i-1],str1[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a22f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  3.2885963171193507e-15\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str2[i-2],str2[i-1],str2[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str2))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e7acf",
   "metadata": {},
   "source": [
    "Modelo de AMLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = math.prod([interpolated_p((str1[i-2],str1[i-1],str1[i]),l[0],l[1],l[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b577f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  3.7097640894512125e-12\n"
     ]
    }
   ],
   "source": [
    "p = math.prod([interpolated_p((str2[i-2],str2[i-1],str2[i]),l[0],l[1],l[2]) for i in range(2,len(str2))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d9862",
   "metadata": {},
   "source": [
    "Simplemente utilizamos los modelos generados anteriormente para probabarlos con nuevas frases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edb0c6",
   "metadata": {},
   "source": [
    "5. Para cada oraci√≥n del punto anterior, haga todas las permutaciones posibles.\n",
    "Calcule su probabilidad a cada nueva frase y muestre el top 3 mas probable y el top 3 menos probable (para ambos modelos de lenguaje). Proponga una frase m√°s y haga lo\n",
    "mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "987b10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "str1_all = list(itertools.permutations(str1)) \n",
    "str2_all = list(itertools.permutations(str2)) \n",
    "str3 = [\"le\",\"mandamos\",\"un\",\"saludo\",\"a\",\"la\",\"mam√°\",\"del\",\"ni√±o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b945c",
   "metadata": {},
   "source": [
    "Modelo de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fa73a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str1_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]    \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "77b68f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.5059032118271946e-13,\n",
       "  ('chingada', 'gano', 'si', 'no', 'me', 'voy', 'a', 'la')),\n",
       " (3.5058285650169387e-13,\n",
       "  ('gano', 'chingada', 'si', 'no', 'me', 'voy', 'a', 'la')),\n",
       " (3.250196286423799e-13,\n",
       "  ('gano', 'chingada', 'no', 'me', 'voy', 'a', 'la', 'si'))]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "77fdf714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.104359258638601e-18,\n",
       "  ('la', 'a', 'gano', 'no', 'chingada', 'voy', 'me', 'si')),\n",
       " (9.105177272879079e-18,\n",
       "  ('la', 'a', 'gano', 'voy', 'no', 'chingada', 'me', 'si')),\n",
       " (9.116838762985829e-18,\n",
       "  ('la', 'a', 'gano', 'me', 'no', 'chingada', 'voy', 'si'))]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1acff912",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str2_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]    \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "09b62545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.233291494329925e-11,\n",
       "  ('acabar', 'corrupci√≥n', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.2332902222389657e-11,\n",
       "  ('corrupci√≥n', 'acabar', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.160360530234272e-11,\n",
       "  ('acabar', 'corrupci√≥n', 'a', 'la', 'ya', 'se', 'va'))]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9d55c8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.6284439153839253e-16,\n",
       "  ('la', 'a', 'corrupci√≥n', 'va', 'se', 'acabar', 'ya')),\n",
       " (1.6324001928727816e-16,\n",
       "  ('la', 'a', 'corrupci√≥n', 'se', 'acabar', 'va', 'ya')),\n",
       " (1.6337257321296207e-16,\n",
       "  ('la', 'a', 'corrupci√≥n', 'va', 'se', 'ya', 'acabar'))]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "50d187fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad:  1.3132416497093299e-16\n"
     ]
    }
   ],
   "source": [
    "#Nueva oraci√≥n dada por mi\n",
    "p = math.prod([interpolated_p((str3[i-2],str3[i-1],str3[i]),l_t[0],l_t[1],l_t[2]) for i in range(2,len(str1))])\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afa60e",
   "metadata": {},
   "source": [
    "Modelo de AMLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fc337809",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str2_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l[0],l[1],l[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]\n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "86a4c754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.4757653325433096e-09,\n",
       "  ('acabar', 'corrupci√≥n', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (2.4605909572043068e-09,\n",
       "  ('corrupci√≥n', 'acabar', 'ya', 'se', 'va', 'a', 'la')),\n",
       " (1.6789815745280819e-09,\n",
       "  ('acabar', 'ya', 'se', 'va', 'a', 'la', 'corrupci√≥n'))]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "af85d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.2435644955463123e-16,\n",
       "  ('a', 'la', 'acabar', 'va', 'se', 'corrupci√≥n', 'ya')),\n",
       " (2.2516676044018094e-16,\n",
       "  ('a', 'la', 'acabar', 'va', 'se', 'ya', 'corrupci√≥n')),\n",
       " (2.267159067556165e-16,\n",
       "  ('a', 'la', 'acabar', 'ya', 'corrupci√≥n', 'va', 'se'))]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc070644",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for st in str1_all:\n",
    "    p += [(math.prod([interpolated_p((st[i-2],st[i-1],st[i]),l[0],l[1],l[2]) for i in range(2,len(st))]),st)]\n",
    "\n",
    "top3 = sorted(p, reverse=True)[:3]   \n",
    "low3 = sorted(p)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9b71a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['le', 'mandamos', 'un', 'saludo', 'a', 'la', 'mam√°', 'del', 'ni√±o']\n",
      "Probabilidad:  3.3470719702831416e-16\n"
     ]
    }
   ],
   "source": [
    "#Nueva oraci√≥n dada por mi\n",
    "p = math.prod([interpolated_p((str3[i-2],str3[i-1],str3[i]),l[0],l[1],l[2]) for i in range(2,len(str1))])\n",
    "print(str3)\n",
    "print(\"Probabilidad: \",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a11fda",
   "metadata": {},
   "source": [
    "Este punto tambi√©n es para evaluar los modelos mediante las permutaciones de las oraciones y la tarea es determinar cual es una oraci√≥n m√°s probable de ser correcta. Los resultados de las top3 fueron buenos, ya que son oraciones con sentido, mientras que las 3 menores fueron lo esperado, oraciones que no tienen sentido. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e00a1b",
   "metadata": {},
   "source": [
    "# (Opcional) El ahorcado (10pts) acumulables solo para tareas: e.g.; esta tarea puede llegar a valer 110/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ec804",
   "metadata": {},
   "source": [
    "Para esta parte estudie y comprenda el funcionamiento de la estrategia propuesta por\n",
    "Norvig http://norvig.com/spell-correct.html. Si√©ntete libre de adaptar y/o extender parcial o\n",
    "totalmente el c√≥digo de Norvig para esta tarea.\n",
    "Dise√±e una funci√≥n que sea capaz de encontrar los caracteres faltantes de una palabra. Para\n",
    "ello proponga una adaptaci√≥n simple de la estrategia de correcci√≥n ortogr√°fica propuesta por\n",
    "Norvig. La funci√≥n de el ahorcado debe poder tratar con hasta 4 caracteres desconocidos en\n",
    "palabras de longitud arbitraria. La funci√≥n debe trabajar en tiempo razonable (‚âà 1 minuto en\n",
    "una laptop o menos). La funci√≥n debe trabajar como sigue con 10 ejemplos:\n",
    "\n",
    "hangman ( \" pe_p_e \" )\n",
    "‚Äô people ‚Äô\n",
    "\n",
    "hangman ( \" phi__sop_y \" )\n",
    "‚Äô philosophy ‚Äô\n",
    "\n",
    "hangman ( \" s i _ n i f _ c _ n c _ \" )\n",
    "‚Äô s i g n i f i c a n c e ‚Äô\n",
    "\n",
    "Puede resolver este punto con una extensi√≥n muy simple de la estrategia de Norvig, o alguna\n",
    "forma m√°s eficiente con distancias de edici√≥n (e.g., Levenshtein) o de subcadenas (e.g., Karp\n",
    "Rabin, Aho-Corasick, Tries, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f84e1",
   "metadata": {},
   "source": [
    "Importamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa49ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'big (4).txt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_pag = 'http://norvig.com/big.txt'\n",
    "pth = ''\n",
    "wget.download(url = url_pag, out = pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e08e5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Funci√≥n del ahorcado\"\n",
    "\n",
    "def words(text): \n",
    "    #return re.findall(r'\\w+', text.lower())\n",
    "    return re.findall('[^\\d\\W]+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def hangman(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or \n",
    "            known(ahorcado_edit1(word)) or \n",
    "            known(ahorcado_edit2(word)) or \n",
    "            known(ahorcado_edit3(word)) or \n",
    "            known(ahorcado_edit4(word)) or \n",
    "            [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def ahorcado_edit1(word):\n",
    "    \"Funci√≥n que trata de adivinar una palabras con hasta 4 letras faltantes\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word)) if word[i]=='_']\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    return set(replaces)\n",
    "\n",
    "def ahorcado_edit2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit1(word) for e2 in ahorcado_edit1(e1))\n",
    "\n",
    "def ahorcado_edit3(word): \n",
    "    \"All edits that are 3 edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit2(word) for e2 in ahorcado_edit1(e1))\n",
    "\n",
    "def ahorcado_edit4(word): \n",
    "    \"All edits that are 4 edits away from `word`.\"\n",
    "    return (e2 for e1 in ahorcado_edit3(word) for e2 in ahorcado_edit1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d54cde",
   "metadata": {},
   "source": [
    "La idea de la funci√≥n es realizar los splits de las palabras, solamente si se encuentra un espacio vac√≠o. Con dicho espacio solamente se realizar√° la operaci√≥n de reemplazo por otra letra. Con esta misma estrategia se buscar√°n posibles palabras reemplazando hasta 4 veces los espacios vac√≠os, (f√°cilmente extendible hasta m√°s letras). Para palabras con m√°s de 1 letra faltante, lo que se hace es realizar los posibles reemplazos con n-1 letras faltantes y luego hacer otro reemplazo extra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92b6bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spelling'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman('sp_l_i__')\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f18c3f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'people'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman ( \"pe_p_e\" )\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3b4d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 0.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'philosophy'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"phi__sop_y\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4785b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'significance'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"si_nif_c_nc_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ee021766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"he__o\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "df32d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'refrigerator'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"refr_g_r_t_r\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "feb11405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'essential'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"e_se__ia_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f79f05b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'languages'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"l__gu_ge_\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a898590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'denmark'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"d__ma__\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0765050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en encontrar la soluci√≥n: 4.07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'europe'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "word = hangman (\"eu____\")\n",
    "end = time()\n",
    "print(\"Tiempo en encontrar la soluci√≥n: %.2f\" % (end-start))\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ec8e7",
   "metadata": {},
   "source": [
    "Comente brevemente como integrar√≠a un modelo de lenguaje con el modelo de Norvig\n",
    "para tratar de resolver errores gramaticales de m√°s alto nivel, o errores d√≥nde el error sea una\n",
    "palabra que si est√° en el diccionario, por ejemplo: \"In the science off Maths ...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21b3d5",
   "metadata": {},
   "source": [
    "Para abordar este problema, se podr√≠a utilizar el modelo de lenguaje para generar una lista de posibles correcciones para la oraci√≥n con errores. A continuaci√≥n, se podr√≠a utilizar el modelo de Norvig para determinar la probabilidad de cada correcci√≥n y elegir la m√°s probable.\n",
    "\n",
    "Una forma de hacer esto ser√≠a:\n",
    "\n",
    "Utilizar el modelo de lenguaje para generar una lista de posibles correcciones para la oraci√≥n con errores. Esto se puede hacer utilizando t√©cnicas de correcci√≥n de errores basadas en modelos de lenguaje, como la correcci√≥n de errores basada en estad√≠sticas o la correcci√≥n de errores basada en redes neuronales.\n",
    "\n",
    "Utilizar el modelo de Norvig para determinar la probabilidad de cada correcci√≥n. El modelo de Norvig utiliza t√©cnicas de procesamiento de lenguaje natural para determinar la probabilidad de una palabra dada en un contexto determinado. En este caso, se podr√≠a utilizar el modelo de Norvig para determinar la probabilidad de cada posible correcci√≥n en el contexto de la oraci√≥n con errores.\n",
    "\n",
    "Elegir la correcci√≥n m√°s probable. Una vez que se han determinado las probabilidades de cada posible correcci√≥n utilizando el modelo de Norvig, se podr√≠a elegir la correcci√≥n m√°s probable como la correcci√≥n sugerida para la oraci√≥n con errores.\n",
    "\n",
    "En el ejemplo dado, \"In the science off Maths ...\" se podr√≠a identificar que \"off\" es una palabra incorrecta y proponer como posible correcci√≥n la palabra \"of\". A continuaci√≥n, el modelo de Norvig podr√≠a determinar la probabilidad de que \"of\" sea la palabra correcta en el contexto de la oraci√≥n, teniendo en cuenta la estructura gramatical y sem√°ntica de la oraci√≥n. Si \"of\" tiene una probabilidad alta, entonces se podr√≠a elegir como la correcci√≥n sugerida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
